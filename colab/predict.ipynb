{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgQllUjD0p87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e77a6b-7179-4920-cdb3-38a41d8c34b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMPM2_La0ul8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c691c2-8e1b-47d5-9ef4-4fb982b106b0"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install git+https://github.com/facebookresearch/fastText.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting git+https://github.com/facebookresearch/fastText.git\n",
            "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-izz3i86x\n",
            "  Running command git clone -q https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-izz3i86x\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (56.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3087878 sha256=dd0f3bc2a9d02a80dbe78df49fd506bdae4a43c2c05b4fb1eeae57447a310360\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sxxwnft3/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d48fmlv7ek7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1571b08-1879-4753-d0a8-ac96b0e2f01c"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install keras==2.2.5\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 42.7MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=468710905fbd97b41edec7114051a2198f8bceefe50980914c5241fd3f21a2a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.5\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-8_z0qdfm\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-8_z0qdfm\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=492206b6628cd280cfd2439609caf2f406edd06c3b7728688dcfc346919c5dd1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5hiznndg/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYwlQRHnfMg1"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import argmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-XKNXF5AMln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5942e447-4182-4008-ce7b-251e297fd386"
      },
      "source": [
        "from keras.models import load_model\n",
        "m = load_model(\"/content/drive/MyDrive/data/input_output/version_1/all_error_v5.h1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKHABcXhSjC3",
        "outputId": "62263176-8eb7-46d7-f3a1-7715afd125b1"
      },
      "source": [
        "!pip install vncorenlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vncorenlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n",
            "\r\u001b[K     |▏                               | 10kB 15.6MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 19.8MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 23.5MB/s eta 0:00:01\r\u001b[K     |▌                               | 40kB 26.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 51kB 26.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 61kB 23.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 71kB 22.2MB/s eta 0:00:01\r\u001b[K     |█                               | 81kB 21.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 92kB 19.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 102kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 112kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 122kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 133kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 143kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 153kB 18.9MB/s eta 0:00:01\r\u001b[K     |██                              | 163kB 18.9MB/s eta 0:00:01\r\u001b[K     |██                              | 174kB 18.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 184kB 18.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 194kB 18.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 204kB 18.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 215kB 18.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 225kB 18.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 235kB 18.9MB/s eta 0:00:01\r\u001b[K     |███                             | 245kB 18.9MB/s eta 0:00:01\r\u001b[K     |███                             | 256kB 18.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 266kB 18.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 276kB 18.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 286kB 18.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 296kB 18.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 307kB 18.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 317kB 18.9MB/s eta 0:00:01\r\u001b[K     |████                            | 327kB 18.9MB/s eta 0:00:01\r\u001b[K     |████                            | 337kB 18.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 348kB 18.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 358kB 18.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 368kB 18.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 378kB 18.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 389kB 18.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 399kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 409kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 419kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 430kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 440kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 450kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 460kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 471kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 481kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 491kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 501kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 512kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 522kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 532kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 542kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 552kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 563kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 573kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 583kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 593kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 604kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 614kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 624kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 634kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 645kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 655kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 665kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 675kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 686kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 696kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 706kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 716kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 727kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 737kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 747kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 757kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 768kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 778kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 788kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 798kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 808kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 819kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 829kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 839kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 849kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 860kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 870kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 880kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 890kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 901kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 911kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 921kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 931kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 942kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 952kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 962kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 972kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 983kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 993kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.7MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.8MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.9MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.0MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.1MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.2MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.3MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.4MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.5MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.6MB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.7MB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp37-none-any.whl size=2645936 sha256=14d10aed42aa809d759d3dc33df2f879d11960e971ce899839baeb00062eda52\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeDy9kM_Sj53",
        "outputId": "09c329cc-3369-4c9d-bb02-1dff2cfb04da"
      },
      "source": [
        "# get word embedding\n",
        "from vncorenlp import VnCoreNLP\n",
        "print('Creating token word...')\n",
        "annotator = VnCoreNLP(\"/content/drive/MyDrive/data/input_output/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "print('token word created')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating token word...\n",
            "token word created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D674NiI6Syo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8558435-b3f7-4822-e2be-3b524f49788f"
      },
      "source": [
        "# aphabet tag library\n",
        "dict_tag = {'pad': 0, 'đường': 1, 'trần': 2, 'thái': 3, 'tông': 4, 'trung': 5, 'hoà': 6, 'cầu': 7, 'giấy': 8, 'hà': 9, 'nội': 10, 'ngõ': 11, 'kính': 12, 'xuân': 13, 'thủy': 14, 'nguyễn': 15, 'chánh': 16, 'ngách': 17, 'phố': 18, 'quốc': 19, 'hoàn': 20, 'dương': 21, 'đình': 22, 'nghệ': 23, 'hẻm': 24, 'mạc': 25, 'yên': 26, 'hoàng': 27, 'minh': 28, 'giám': 29, 'doãn': 30, 'kế': 31, 'thiện': 32, 'mai': 33, 'dịch': 34, 'lạc': 35, 'long': 36, 'quân': 37, 'nghĩa': 38, 'đô': 39, 'giao': 40, 'lộ': 41, 'đoạn': 42, 'quay': 43, 'đầu': 44, 'võ': 45, 'chí': 46, 'công': 47, 'ngọc': 48, 'vũ': 49, 'thị': 50, 'định': 51, 'lê': 52, 'văn': 53, 'lương': 54, 'ngân': 55, 'duy': 56, 'hưng': 57, 'lô': 58, 'vọng': 59, 'hậu': 60, 'tân': 61, 'việt': 62, 'hòa': 63, 'bưởi': 64, 'cửa': 65, 'hàng': 66, 'rồng': 67, 'biển': 68, 'khuất': 69, 'tiến': 70, 'khang': 71, 'khu': 72, 'nhân': 73, 'chính': 74, 'đỗ': 75, 'quang': 76, 'khánh': 77, 'toàn': 78, 'quan': 79, 'hoa': 80, 'đông': 81, 'sâm': 82, 'nhà': 83, 'nghỉ': 84, 'bình': 85, 'ocerbank': 86, 'ảnh': 87, 'viện': 88, 'piano': 89, 'bảo': 90, 'tàng': 91, 'dân': 92, 'tộc': 93, 'học': 94, 'nam': 95, 'tạp': 96, 'hóa': 97, 'trường': 98, 'cao': 99, 'đẳng': 100, 'cộng': 101, 'đồng': 102, 'tòa': 103, 'phòng': 104, 'tâm': 105, 'ngoại': 106, 'ngữ': 107, 'tin': 108, 'nghiệp': 109, 'vụ': 110, 'và': 111, 'tư': 112, 'vấn': 113, 'chuyên': 114, 'sửa': 115, 'chữa': 116, '-': 117, 'dưỡng': 118, 'xe': 119, 'ga': 120, 'số': 121, 'đất': 122, 'an': 123, 'phú': 124, 'khám': 125, 'nga': 126, 'chung': 127, 'cư': 128, 'phẩm': 129, 'quà': 130, 'tặng': 131, 'đồ': 132, 'chơi': 133, 'quán': 134, 'cà': 135, 'phê': 136, 'highlands': 137, 'kim': 138, 'khí': 139, 'điện': 140, 'dụng': 141, 'ánh': 142, 'tuyết': 143, 'ty': 144, 'sơn': 145, 'huyên': 146, 'xí': 147, 'phát': 148, 'triển': 149, 'hạ': 150, 'tầng': 151, 'sinh': 152, 'viên': 153, 'tí': 154, 'cồ': 155, 'phở': 156, 'bò': 157, 'khách': 158, 'sạn': 159, 'ngôi': 160, 'sao': 161, 'phân': 162, 'phối': 163, 'thiết': 164, 'bị': 165, 'panasonic': 166, 'phúc': 167, 'lòng': 168, 'cháo': 169, 'thời': 170, 'trang': 171, 'figo': 172, 'sgop': 173, 'chứng': 174, 'phùng': 175, 'kiên': 176, 'bánh': 177, 'thu': 178, 'hữu': 179, 'nghị': 180, 'cp': 181, 'tử': 182, 'chất': 183, 'máy': 184, 'thuấn': 185, 'salon': 186, 'tóc': 187, 'phương': 188, 'thuy': 189, 'linh': 190, 'star': 191, 'tnhh': 192, 'đào': 193, 'tạo': 194, 'ipass': 195, 'cơm': 196, 'ngon': 197, 'kcc': 198, 'vivi': 199, 'truyền': 200, 'thông': 201, 'lâm': 202, 'thanh': 203, 'thoại': 204, 'mobile': 205, 'thực': 206, 'chức': 207, 'năng': 208, 'mỹ': 209, 'miss': 210, 'anna': 211, 'made': 212, 'in': 213, 'café': 214, 'hát': 215, 'cho': 216, 'nhau': 217, 'nghe': 218, 'thành': 219, 'biên': 220, 'lốp': 221, 'ắc': 222, 'quy': 223, 'ôtô': 224, 'castrol': 225, 'bike': 226, 'point': 227, 'vel': 228, 'city': 229, 'phạm': 230, 'thận': 231, 'duật': 232, 'thương': 233, 'mại': 234, 'xuất': 235, 'nhập': 236, 'khẩu': 237, 'vật': 238, 'nước': 239, 'cổ': 240, 'phần': 241, 'vsi': 242, 'gà': 243, 'tần': 244, 'bún': 245, 'chả': 246, 'onyx': 247, 'giặt': 248, 'là': 249, 'thuốc': 250, 'hải': 251, 've': 252, 'trẻ': 253, 'em': 254, 'cung': 255, 'đăng': 256, 'ninh': 257, 'cô': 258, 'lan': 259, 'quả': 260, 'kẹo': 261, 'tô': 262, 'hiệu': 263, 'taxi': 264, 'triệu': 265, 'đạt': 266, 'gara': 267, 'ô': 268, 'giải': 269, 'khát': 270, 'thảo': 271, 'huy': 272, 'thao': 273, 'viet': 274, 'ceramics': 275, 'thất': 276, 'iki': 277, 'decor': 278, 'techcombank': 279, 'đại': 280, 'lý': 281, 'vé': 282, 'bay': 283, 'chuỗi': 284, 'cá': 285, 'rửa': 286, 'món': 287, 'huế': 288, 'hàm': 289, 'thịnh': 290, 'soya': 291, 'garden': 292, 'vàng': 293, 'mã': 294, 'pooltek': 295, 'tế': 296, 'ngành': 297, 'đức': 298, 'gạch': 299, 'ốp': 300, 'lát': 301, 'vệ': 302, 'song': 303}\n",
        "aphabet_tag = []\n",
        "for key, value in dict_tag.items():\n",
        "  aphabet_tag.append(key)\n",
        "print(aphabet_tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['pad', 'đường', 'trần', 'thái', 'tông', 'trung', 'hoà', 'cầu', 'giấy', 'hà', 'nội', 'ngõ', 'kính', 'xuân', 'thủy', 'nguyễn', 'chánh', 'ngách', 'phố', 'quốc', 'hoàn', 'dương', 'đình', 'nghệ', 'hẻm', 'mạc', 'yên', 'hoàng', 'minh', 'giám', 'doãn', 'kế', 'thiện', 'mai', 'dịch', 'lạc', 'long', 'quân', 'nghĩa', 'đô', 'giao', 'lộ', 'đoạn', 'quay', 'đầu', 'võ', 'chí', 'công', 'ngọc', 'vũ', 'thị', 'định', 'lê', 'văn', 'lương', 'ngân', 'duy', 'hưng', 'lô', 'vọng', 'hậu', 'tân', 'việt', 'hòa', 'bưởi', 'cửa', 'hàng', 'rồng', 'biển', 'khuất', 'tiến', 'khang', 'khu', 'nhân', 'chính', 'đỗ', 'quang', 'khánh', 'toàn', 'quan', 'hoa', 'đông', 'sâm', 'nhà', 'nghỉ', 'bình', 'ocerbank', 'ảnh', 'viện', 'piano', 'bảo', 'tàng', 'dân', 'tộc', 'học', 'nam', 'tạp', 'hóa', 'trường', 'cao', 'đẳng', 'cộng', 'đồng', 'tòa', 'phòng', 'tâm', 'ngoại', 'ngữ', 'tin', 'nghiệp', 'vụ', 'và', 'tư', 'vấn', 'chuyên', 'sửa', 'chữa', '-', 'dưỡng', 'xe', 'ga', 'số', 'đất', 'an', 'phú', 'khám', 'nga', 'chung', 'cư', 'phẩm', 'quà', 'tặng', 'đồ', 'chơi', 'quán', 'cà', 'phê', 'highlands', 'kim', 'khí', 'điện', 'dụng', 'ánh', 'tuyết', 'ty', 'sơn', 'huyên', 'xí', 'phát', 'triển', 'hạ', 'tầng', 'sinh', 'viên', 'tí', 'cồ', 'phở', 'bò', 'khách', 'sạn', 'ngôi', 'sao', 'phân', 'phối', 'thiết', 'bị', 'panasonic', 'phúc', 'lòng', 'cháo', 'thời', 'trang', 'figo', 'sgop', 'chứng', 'phùng', 'kiên', 'bánh', 'thu', 'hữu', 'nghị', 'cp', 'tử', 'chất', 'máy', 'thuấn', 'salon', 'tóc', 'phương', 'thuy', 'linh', 'star', 'tnhh', 'đào', 'tạo', 'ipass', 'cơm', 'ngon', 'kcc', 'vivi', 'truyền', 'thông', 'lâm', 'thanh', 'thoại', 'mobile', 'thực', 'chức', 'năng', 'mỹ', 'miss', 'anna', 'made', 'in', 'café', 'hát', 'cho', 'nhau', 'nghe', 'thành', 'biên', 'lốp', 'ắc', 'quy', 'ôtô', 'castrol', 'bike', 'point', 'vel', 'city', 'phạm', 'thận', 'duật', 'thương', 'mại', 'xuất', 'nhập', 'khẩu', 'vật', 'nước', 'cổ', 'phần', 'vsi', 'gà', 'tần', 'bún', 'chả', 'onyx', 'giặt', 'là', 'thuốc', 'hải', 've', 'trẻ', 'em', 'cung', 'đăng', 'ninh', 'cô', 'lan', 'quả', 'kẹo', 'tô', 'hiệu', 'taxi', 'triệu', 'đạt', 'gara', 'ô', 'giải', 'khát', 'thảo', 'huy', 'thao', 'viet', 'ceramics', 'thất', 'iki', 'decor', 'techcombank', 'đại', 'lý', 'vé', 'bay', 'chuỗi', 'cá', 'rửa', 'món', 'huế', 'hàm', 'thịnh', 'soya', 'garden', 'vàng', 'mã', 'pooltek', 'tế', 'ngành', 'đức', 'gạch', 'ốp', 'lát', 'vệ', 'song']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAVbVKV3ZpgG"
      },
      "source": [
        "#get char embedding\n",
        "def read_char_vocab(file_path):\n",
        "  char_vocab = []\n",
        "  for line in open(file_path, encoding='utf-8'):\n",
        "    char_vocab.append(line.splitlines()[0])      \n",
        "  return char_vocab\n",
        "\n",
        "def char_to_int(char_vocab_data):\n",
        "  dic = {}\n",
        "  index = -1\n",
        "  for char in char_vocab_data:\n",
        "    try:\n",
        "      dic[char]\n",
        "    except:\n",
        "      index = index + 1\n",
        "      dic[char]=index\n",
        "  return dic\n",
        " \n",
        "def get_char_encode(sentence,max_length_of_a_sentence,max_length_of_a_word):\n",
        "  char_vocab_data = read_char_vocab(\"/content/drive/MyDrive/data/VISCII_short.txt\")\n",
        "  dic = char_to_int(char_vocab_data)\n",
        "  # sentence  words is a sentence | ['i','am','an']\n",
        "  sentence_encoded = np.zeros([max_length_of_a_sentence,max_length_of_a_word]) # 25*25\n",
        "  for j in range(len(sentence)):  \n",
        "    word = sentence[j].lower()\n",
        "    # integer_encoded = [char_to_int[char] for char in word]\n",
        "    word_encoded = np.zeros(max_length_of_a_word)\n",
        "    for k in range(len(word)):\n",
        "      char = word[k]\n",
        "      try:\n",
        "        word_encoded[k]= dic[char]\n",
        "      except:\n",
        "        print(\"error : \" + str(char)+\" \"+str(word)+\" \"+str(len(word)))\n",
        "        word_encoded[k]= dic['[unk]']\n",
        "    # sentence encoded\n",
        "    sentence_encoded[j] = word_encoded\n",
        "  return sentence_encoded\n",
        "\n",
        "def get_charEmbedd_form_encode(charEnocde):\n",
        "  LEN_OF_VOCAB = 137\n",
        "  shape = charEnocde.shape\n",
        "  char_embedd = np.zeros([shape[0],shape[1],LEN_OF_VOCAB])\n",
        "  for i in range(shape[0]):\n",
        "    for j in range(shape[1]):\n",
        "      char_int = charEnocde[i,j]\n",
        "      char_int = char_int.astype(np.int64)\n",
        "      onehot = np.zeros(LEN_OF_VOCAB)\n",
        "      onehot[char_int] = 1\n",
        "      char_embedd[i,j,:] = onehot\n",
        "  return char_embedd\n",
        "\n",
        "# return onehot_encoded_of_a_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkdZwHxH362H",
        "outputId": "dc6efebb-d998-45c2-c8a5-f9f89a846dbc"
      },
      "source": [
        "!unzip /content/drive/MyDrive/data/input_output/ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/data/input_output/ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BloS0Pnz4UA5",
        "outputId": "6be9a025-b665-483b-f6e9-5e771365dfdb"
      },
      "source": [
        "!./ngrok authtoken 1qsqOzbDZdLDHX24amcZKpNbMaL_7pzRyPRjA8gFp1pMNY37w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpc-WtVkMJ2s"
      },
      "source": [
        "def check_number_contain(s):\n",
        "    check = False if next((chr for chr in s if chr.isdigit()), None) else True\n",
        "    return check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-opCmTfYVEG",
        "outputId": "df89ad42-b154-4676-d96d-29c50afd05a1"
      },
      "source": [
        "query = \"144 xaun thủ cau giay ha noi\"\n",
        "# try:\n",
        "#   sen_words = query.split()\n",
        "#   num_of_word = len(sen_words)\n",
        "# except:\n",
        "#   print('Creating token word...')\n",
        "# #   annotator = VnCoreNLP(\"/content/drive/MyDrive/data/input_output/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "#   print('token word created')\n",
        "#   sen_words = query.split()\n",
        "#   num_of_word = len(sen_words)\n",
        "\n",
        "\n",
        "sen_words = query.split()\n",
        "# num_of_word = len(sen_words)\n",
        "\n",
        "temp_word = []\n",
        "result = []\n",
        "for i in sen_words:\n",
        "  if check_number_contain(i):\n",
        "    temp_word.append(i)\n",
        "    result.append(\"\")\n",
        "  else:\n",
        "    result.append(i)\n",
        "num_of_word = len(temp_word)\n",
        "\n",
        "print(sen_words)\n",
        "# print(result)\n",
        "# print(temp_word)\n",
        "\n",
        "# get char embedding\n",
        "char_encode = get_char_encode(temp_word, 25, 25)\n",
        "\n",
        "char_embedd = get_charEmbedd_form_encode(char_encode)\n",
        "char_embedd = char_embedd.reshape(1,char_embedd.shape[0], char_embedd.shape[1],char_embedd.shape[2])\n",
        "\n",
        "# # predict\n",
        "output = m.predict([char_embedd])\n",
        "\n",
        "# return [1,2,3,4,5,5,5,5,5,5,5,5,5,5,5] or convert to encode tag\n",
        "tag_encode = []\n",
        "for i in range(25): \n",
        "  tag_encode.append(argmax(output[0,i,:]))\n",
        "\n",
        "tag_result=[]\n",
        "for i in range(num_of_word):\n",
        "  tag_result.append(aphabet_tag[tag_encode[i]])\n",
        "  arr_tag_result=np.array(tag_result)\n",
        "# print(tag_result)\n",
        "\n",
        "count = 0\n",
        "while count < len(tag_result):\n",
        "  for i in range(len(result)):\n",
        "    if result[i] == '':\n",
        "      result[i] = tag_result[count]\n",
        "      count = count + 1\n",
        "\n",
        "print(result)\n",
        "\n",
        "# result = []\n",
        "# for i in tag_result:\n",
        "#   result.append(i)\n",
        "\n",
        "# for i in range(len(temp)):\n",
        "#   if temp[i] == \"\":\n",
        "#     result[i] = sen_words[i]\n",
        "\n",
        "# print(result)\n",
        "# print(len(temp))\n",
        "# print(len(tag_result))\n",
        "\n",
        "# print(tag_result)\n",
        "\n",
        "# for i in range(len(sen_words)):\n",
        "#   if check_number_contain(sen_words) == True:\n",
        "#     result.append(tag_result[i])\n",
        "#   result.append(sen_words[i])\n",
        "\n",
        "# print(result)\n",
        "\n",
        "# return {'nhaf_hàng': OBJ,....} \n",
        "# result={}\n",
        "# for i in range(num_of_word):\n",
        "#   result[sen_words[i]] = str(arr_tag_result[i])\n",
        "\n",
        "# print(result)\n",
        "#==========================\n",
        "# dic_result = {}\n",
        "# for word in result:\n",
        "#   tag = result[word]\n",
        "#   try:\n",
        "#     dic_result[tag] += \" \" + word\n",
        "#   except:\n",
        "#     dic_result[tag] = word\n",
        "# print(dic_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['144', 'xaun', 'thủ', 'cau', 'giay', 'ha', 'noi']\n",
            "['144', 'xuân', 'thủy', 'cầu', 'giấy', 'hà', 'nội']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kssvB0jYrAef",
        "outputId": "1ad5e28d-0d86-47dd-db22-606cdbbe027b"
      },
      "source": [
        "import requests\n",
        "#from flask import Flask, render_template, jsonify\n",
        "from flask import Flask, render_template, abort, request, jsonify, json,Response\n",
        "from flask import request, redirect, url_for\n",
        "import codecs\n",
        "import gensim\n",
        "from distutils.version import LooseVersion, StrictVersion\n",
        "import json\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "app.config['JSON_AS_ASCII'] = False\n",
        "\n",
        "global word2vec_model\n",
        "\n",
        "@app.route('/')\n",
        "def summary():\n",
        "  if request.method == \"GET\":\n",
        "    query = request.values['query'] or ''\n",
        "    query = str(query)\n",
        "    print( 'query = ' + query )\n",
        "    \n",
        "    # token word\n",
        "    try:\n",
        "      # sen_words = annotator.tokenize(query)[0]\n",
        "      # num_of_word = len(sen_words)\n",
        "      sen_words = query.split()\n",
        "      num_of_word = len(sen_words)\n",
        "    except:\n",
        "      print('Creating token word...')\n",
        "      # annotator = VnCoreNLP(\"/content/drive/MyDrive/data/input_output/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "      print('token word created')\n",
        "      sen_words = query.split()\n",
        "      num_of_word = len(sen_words)\n",
        "    print(sen_words)\n",
        "        \n",
        "    # get char embedding\n",
        "    char_encode = get_char_encode(sen_words,25,25)\n",
        "\n",
        "    char_embedd = get_charEmbedd_form_encode(char_encode)\n",
        "    char_embedd = char_embedd.reshape(1,char_embedd.shape[0], char_embedd.shape[1],char_embedd.shape[2])\n",
        "\n",
        "    # predict\n",
        "    output = m.predict([char_embedd])\n",
        "\n",
        "    # return [1,2,3,4,5,5,5,5,5,5,5,5,5,5,5] or convert to encode tag\n",
        "    tag_encode = []\n",
        "    for i in range(25): \n",
        "      tag_encode.append(argmax(output[0,i,:]))\n",
        "\n",
        "    # return [street, homenumber,.....] or only get [num_of_word] first element=> convert to tag\n",
        "    tag_result=[]\n",
        "    for i in range(num_of_word):\n",
        "      tag_result.append(aphabet_tag[tag_encode[i]])\n",
        "      arr_tag_result=np.array(tag_result)\n",
        "\n",
        "    print(tag_result)\n",
        "\n",
        "    return jsonify(sen_words=sen_words, tags=tag_result)\n",
        "if __name__ == \"__main__\":\n",
        "  import os\n",
        "  app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://4c435ab1769c.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2021-04-28 16:09:22,182] ERROR in app: Exception on / [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-17-298438728275>\", line 39, in summary\n",
            "    char_encode = get_char_encode(sen_words,25,25)\n",
            "  File \"<ipython-input-14-dd7e26e21242>\", line 23, in get_char_encode\n",
            "    sentence_encoded = np.zeros([max_length_of_a_sentence,max_length_of_a_word]) # 25*25\n",
            "NameError: name 'np' is not defined\n",
            "127.0.0.1 - - [28/Apr/2021 16:09:22] \"\u001b[35m\u001b[1mGET /?query=144%20xuân%20thủ%20cầu%20giấy%20hà%20nội HTTP/1.1\u001b[0m\" 500 -\n",
            "127.0.0.1 - - [28/Apr/2021 16:09:22] \"\u001b[33mGET /robots.txt HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "query = 144 xuân thủ cầu giấy hà nội\n",
            "['144', 'xuân', 'thủ', 'cầu', 'giấy', 'hà', 'nội']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [28/Apr/2021 16:09:23] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}