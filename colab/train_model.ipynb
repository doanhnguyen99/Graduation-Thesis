{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of doanh.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD3MR4JHNjSI",
        "outputId": "c6854948-09d2-4043-f7e6-e334771461fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRBYVW4LNx2F",
        "outputId": "76168943-f776-4117-c255-10c1b726327c"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install keras==2.2.5\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 33kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (56.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=e9babb8d5bf76915bae16f8a9b94c89419a6069923aada2555a5779e7fed5584\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.5\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-spfpl42a\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-spfpl42a\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=302089319a647d43f4e2357ce9bb424f2312fc23d3404b04ffdfbc95ddda5c73\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7rny_zfm/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn9ebWuzN-BZ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v1fR3f6OBKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6242aec3-3cb6-4ef1-d2b9-382ba052bc5a"
      },
      "source": [
        "from keras.models import Sequential, Model, Input, load_model\n",
        "from keras.layers import LSTM, Dense, TimeDistributed, Activation, Bidirectional, Masking, Embedding, Dropout, Flatten, concatenate, Conv1D, MaxPool1D\n",
        "from keras import backend as K\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras_contrib.losses import  crf_loss\n",
        "from keras_contrib.metrics import crf_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltZAxR77OF0h",
        "outputId": "60d3750b-cad8-4015-c36d-5c734318b192"
      },
      "source": [
        "def building_ner(num_hidden_node, dropout, time_step, vector_length, output_lenght):\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=(25, time_step, vector_length)))\n",
        "\n",
        "    model.add(TimeDistributed (LSTM(units=num_hidden_node, return_sequences=False, dropout=dropout, recurrent_dropout=dropout)) )\n",
        "\n",
        "    model.add( LSTM(units=num_hidden_node, return_sequences=True, dropout=dropout, recurrent_dropout=dropout) )\n",
        "\n",
        "    model.add(TimeDistributed(Dense(output_lenght)))\n",
        "    \n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    plot_model(model, \"demo.png\", show_shapes=True)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = building_ner(num_hidden_node = 32, dropout = 0.2, time_step = 25, vector_length = 137, output_lenght = 304)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "masking_1 (Masking)          (None, 25, 25, 137)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 25, 32)            21760     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 25, 32)            8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 25, 304)           10032     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 25, 304)           0         \n",
            "=================================================================\n",
            "Total params: 40,112\n",
            "Trainable params: 40,112\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNrQwbt9okD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70fa1b58-0ccc-4fd0-da3e-5e4b97950d17"
      },
      "source": [
        "tag = np.loadtxt('/content/drive/MyDrive/data/tag_encode_input/version_2/all_error_v3.txt')\n",
        "print(tag.shape)\n",
        "char_encode = np.loadtxt('/content/drive/MyDrive/data/char_encode_input/version_2/all_error_v3.txt')\n",
        "print(char_encode.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(196750, 304)\n",
            "(196750, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-W7MfPDo9Tg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9558460f-6621-4e9a-9f08-fb083dd55aa3"
      },
      "source": [
        "tag = tag.reshape(int(tag.shape[0]/25), 25, tag.shape[1])\n",
        "print(tag.shape)\n",
        "#new\n",
        "char_encode = char_encode.reshape(int(char_encode.shape[0]/25), 25, char_encode.shape[1])\n",
        "print(char_encode.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7870, 25, 304)\n",
            "(7870, 25, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00XtWSWVpKPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff68d47d-d352-4c5c-82a0-4ee41815612c"
      },
      "source": [
        "# chuyển từ char encode sang char embedding\n",
        "LEN_OF_VOCAB = 137\n",
        "shape = char_encode.shape\n",
        "char_embedd = np.zeros([shape[0],shape[1],shape[2],LEN_OF_VOCAB])\n",
        "for i in range(shape[0]):\n",
        "  for j in range(shape[1]):\n",
        "    for k in range(shape[2]):\n",
        "      char_int = char_encode[i,j,k]\n",
        "      char_int = char_int.astype(np.int64)\n",
        "      onehot = np.zeros(LEN_OF_VOCAB)\n",
        "      onehot[char_int] = 1\n",
        "      char_embedd[i,j,k,:] = onehot\n",
        "\n",
        "print(char_embedd.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7870, 25, 25, 137)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0NPMzl2pYEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341ee734-84f7-491f-805e-09c21c15290f"
      },
      "source": [
        "import keras\n",
        "\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(filepath='/content/drive/MyDrive/data/input_output/version_1/all_error_v5.h1', verbose=1, save_best_only=True)\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='acc', patience=5)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(char_embedd, tag, test_size=0.1)\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(X_train, \n",
        "          y_train,\n",
        "          epochs=500,\n",
        "          batch_size = 64,\n",
        "          validation_data=(X_test, y_test),\n",
        ")\n",
        "# Pass callback to training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 7083 samples, validate on 787 samples\n",
            "Epoch 1/500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7083/7083 [==============================] - 47s 7ms/step - loss: 3.3125 - acc: 0.5722 - val_loss: 1.9267 - val_acc: 0.6075\n",
            "Epoch 2/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 1.7267 - acc: 0.6169 - val_loss: 1.5438 - val_acc: 0.6319\n",
            "Epoch 3/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 1.4625 - acc: 0.6507 - val_loss: 1.3602 - val_acc: 0.6687\n",
            "Epoch 4/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 1.3279 - acc: 0.6726 - val_loss: 1.2904 - val_acc: 0.6857\n",
            "Epoch 5/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 1.2575 - acc: 0.6843 - val_loss: 1.2294 - val_acc: 0.6966\n",
            "Epoch 6/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 1.2102 - acc: 0.6935 - val_loss: 1.1897 - val_acc: 0.7119\n",
            "Epoch 7/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 1.1738 - acc: 0.6997 - val_loss: 1.1693 - val_acc: 0.7105\n",
            "Epoch 8/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 1.1467 - acc: 0.7047 - val_loss: 1.1402 - val_acc: 0.7105\n",
            "Epoch 9/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 1.1239 - acc: 0.7069 - val_loss: 1.1240 - val_acc: 0.7105\n",
            "Epoch 10/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 1.1054 - acc: 0.7077 - val_loss: 1.1065 - val_acc: 0.7105\n",
            "Epoch 11/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 1.0778 - acc: 0.7218 - val_loss: 1.0429 - val_acc: 0.7576\n",
            "Epoch 12/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 1.0284 - acc: 0.7469 - val_loss: 0.9952 - val_acc: 0.7731\n",
            "Epoch 13/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.9809 - acc: 0.7614 - val_loss: 0.9306 - val_acc: 0.7965\n",
            "Epoch 14/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.9245 - acc: 0.7783 - val_loss: 0.8644 - val_acc: 0.8083\n",
            "Epoch 15/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 0.8634 - acc: 0.8002 - val_loss: 0.8067 - val_acc: 0.8301\n",
            "Epoch 16/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 0.8078 - acc: 0.8219 - val_loss: 0.7472 - val_acc: 0.8467\n",
            "Epoch 17/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.7590 - acc: 0.8323 - val_loss: 0.7020 - val_acc: 0.8502\n",
            "Epoch 18/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.7155 - acc: 0.8409 - val_loss: 0.6593 - val_acc: 0.8625\n",
            "Epoch 19/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.6734 - acc: 0.8505 - val_loss: 0.6159 - val_acc: 0.8693\n",
            "Epoch 20/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.6293 - acc: 0.8608 - val_loss: 0.5638 - val_acc: 0.8743\n",
            "Epoch 21/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.5843 - acc: 0.8696 - val_loss: 0.5220 - val_acc: 0.8814\n",
            "Epoch 22/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.5387 - acc: 0.8805 - val_loss: 0.4858 - val_acc: 0.8931\n",
            "Epoch 23/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.5063 - acc: 0.8898 - val_loss: 0.4538 - val_acc: 0.9042\n",
            "Epoch 24/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.4780 - acc: 0.8963 - val_loss: 0.4258 - val_acc: 0.9175\n",
            "Epoch 25/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.4501 - acc: 0.9036 - val_loss: 0.4023 - val_acc: 0.9181\n",
            "Epoch 26/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.4242 - acc: 0.9085 - val_loss: 0.3764 - val_acc: 0.9223\n",
            "Epoch 27/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.4025 - acc: 0.9141 - val_loss: 0.3516 - val_acc: 0.9295\n",
            "Epoch 28/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.3809 - acc: 0.9190 - val_loss: 0.3316 - val_acc: 0.9349\n",
            "Epoch 29/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.3571 - acc: 0.9249 - val_loss: 0.3107 - val_acc: 0.9395\n",
            "Epoch 30/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.3390 - acc: 0.9295 - val_loss: 0.2938 - val_acc: 0.9438\n",
            "Epoch 31/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 0.3226 - acc: 0.9332 - val_loss: 0.2780 - val_acc: 0.9437\n",
            "Epoch 32/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.3040 - acc: 0.9364 - val_loss: 0.2624 - val_acc: 0.9483\n",
            "Epoch 33/500\n",
            "7083/7083 [==============================] - 43s 6ms/step - loss: 0.2905 - acc: 0.9391 - val_loss: 0.2476 - val_acc: 0.9501\n",
            "Epoch 34/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.2790 - acc: 0.9408 - val_loss: 0.2353 - val_acc: 0.9517\n",
            "Epoch 35/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.2638 - acc: 0.9439 - val_loss: 0.2228 - val_acc: 0.9533\n",
            "Epoch 36/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.2507 - acc: 0.9465 - val_loss: 0.2127 - val_acc: 0.9545\n",
            "Epoch 37/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.2411 - acc: 0.9480 - val_loss: 0.2022 - val_acc: 0.9566\n",
            "Epoch 38/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.2301 - acc: 0.9496 - val_loss: 0.1919 - val_acc: 0.9582\n",
            "Epoch 39/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.2227 - acc: 0.9510 - val_loss: 0.1854 - val_acc: 0.9589\n",
            "Epoch 40/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.2140 - acc: 0.9528 - val_loss: 0.1776 - val_acc: 0.9609\n",
            "Epoch 41/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.2078 - acc: 0.9539 - val_loss: 0.1713 - val_acc: 0.9611\n",
            "Epoch 42/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1984 - acc: 0.9556 - val_loss: 0.1626 - val_acc: 0.9630\n",
            "Epoch 43/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1907 - acc: 0.9574 - val_loss: 0.1586 - val_acc: 0.9647\n",
            "Epoch 44/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1841 - acc: 0.9585 - val_loss: 0.1499 - val_acc: 0.9663\n",
            "Epoch 45/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1772 - acc: 0.9602 - val_loss: 0.1435 - val_acc: 0.9667\n",
            "Epoch 46/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1732 - acc: 0.9611 - val_loss: 0.1390 - val_acc: 0.9680\n",
            "Epoch 47/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1667 - acc: 0.9625 - val_loss: 0.1331 - val_acc: 0.9701\n",
            "Epoch 48/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1601 - acc: 0.9636 - val_loss: 0.1277 - val_acc: 0.9707\n",
            "Epoch 49/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1567 - acc: 0.9643 - val_loss: 0.1244 - val_acc: 0.9709\n",
            "Epoch 50/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1513 - acc: 0.9652 - val_loss: 0.1187 - val_acc: 0.9724\n",
            "Epoch 51/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1459 - acc: 0.9664 - val_loss: 0.1138 - val_acc: 0.9734\n",
            "Epoch 52/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1401 - acc: 0.9674 - val_loss: 0.1093 - val_acc: 0.9735\n",
            "Epoch 53/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1357 - acc: 0.9686 - val_loss: 0.1054 - val_acc: 0.9744\n",
            "Epoch 54/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1316 - acc: 0.9694 - val_loss: 0.1020 - val_acc: 0.9753\n",
            "Epoch 55/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1298 - acc: 0.9696 - val_loss: 0.0992 - val_acc: 0.9754\n",
            "Epoch 56/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1241 - acc: 0.9709 - val_loss: 0.0952 - val_acc: 0.9769\n",
            "Epoch 57/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1199 - acc: 0.9720 - val_loss: 0.0908 - val_acc: 0.9779\n",
            "Epoch 58/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1169 - acc: 0.9726 - val_loss: 0.0879 - val_acc: 0.9781\n",
            "Epoch 59/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1136 - acc: 0.9730 - val_loss: 0.0846 - val_acc: 0.9791\n",
            "Epoch 60/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1103 - acc: 0.9738 - val_loss: 0.0823 - val_acc: 0.9807\n",
            "Epoch 61/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1074 - acc: 0.9745 - val_loss: 0.0784 - val_acc: 0.9812\n",
            "Epoch 62/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1038 - acc: 0.9755 - val_loss: 0.0754 - val_acc: 0.9819\n",
            "Epoch 63/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.1016 - acc: 0.9757 - val_loss: 0.0725 - val_acc: 0.9831\n",
            "Epoch 64/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0982 - acc: 0.9768 - val_loss: 0.0711 - val_acc: 0.9836\n",
            "Epoch 65/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0944 - acc: 0.9775 - val_loss: 0.0678 - val_acc: 0.9847\n",
            "Epoch 66/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0910 - acc: 0.9784 - val_loss: 0.0657 - val_acc: 0.9855\n",
            "Epoch 67/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0903 - acc: 0.9785 - val_loss: 0.0632 - val_acc: 0.9861\n",
            "Epoch 68/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0856 - acc: 0.9797 - val_loss: 0.0607 - val_acc: 0.9864\n",
            "Epoch 69/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0842 - acc: 0.9803 - val_loss: 0.0586 - val_acc: 0.9872\n",
            "Epoch 70/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0821 - acc: 0.9809 - val_loss: 0.0566 - val_acc: 0.9878\n",
            "Epoch 71/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0801 - acc: 0.9813 - val_loss: 0.0539 - val_acc: 0.9885\n",
            "Epoch 72/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0786 - acc: 0.9815 - val_loss: 0.0531 - val_acc: 0.9886\n",
            "Epoch 73/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0762 - acc: 0.9821 - val_loss: 0.0512 - val_acc: 0.9889\n",
            "Epoch 74/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0735 - acc: 0.9828 - val_loss: 0.0485 - val_acc: 0.9893\n",
            "Epoch 75/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0718 - acc: 0.9830 - val_loss: 0.0476 - val_acc: 0.9898\n",
            "Epoch 76/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0711 - acc: 0.9831 - val_loss: 0.0457 - val_acc: 0.9904\n",
            "Epoch 77/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0693 - acc: 0.9839 - val_loss: 0.0445 - val_acc: 0.9903\n",
            "Epoch 78/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0671 - acc: 0.9845 - val_loss: 0.0434 - val_acc: 0.9909\n",
            "Epoch 79/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0652 - acc: 0.9852 - val_loss: 0.0408 - val_acc: 0.9920\n",
            "Epoch 80/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0636 - acc: 0.9854 - val_loss: 0.0399 - val_acc: 0.9917\n",
            "Epoch 81/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0611 - acc: 0.9861 - val_loss: 0.0387 - val_acc: 0.9924\n",
            "Epoch 82/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0607 - acc: 0.9861 - val_loss: 0.0374 - val_acc: 0.9928\n",
            "Epoch 83/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0590 - acc: 0.9863 - val_loss: 0.0360 - val_acc: 0.9928\n",
            "Epoch 84/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0585 - acc: 0.9864 - val_loss: 0.0352 - val_acc: 0.9932\n",
            "Epoch 85/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0570 - acc: 0.9869 - val_loss: 0.0338 - val_acc: 0.9937\n",
            "Epoch 86/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0546 - acc: 0.9875 - val_loss: 0.0326 - val_acc: 0.9940\n",
            "Epoch 87/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0538 - acc: 0.9877 - val_loss: 0.0316 - val_acc: 0.9943\n",
            "Epoch 88/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0531 - acc: 0.9878 - val_loss: 0.0301 - val_acc: 0.9944\n",
            "Epoch 89/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0514 - acc: 0.9881 - val_loss: 0.0298 - val_acc: 0.9941\n",
            "Epoch 90/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0517 - acc: 0.9882 - val_loss: 0.0283 - val_acc: 0.9946\n",
            "Epoch 91/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0496 - acc: 0.9888 - val_loss: 0.0276 - val_acc: 0.9951\n",
            "Epoch 92/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0487 - acc: 0.9888 - val_loss: 0.0266 - val_acc: 0.9951\n",
            "Epoch 93/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0481 - acc: 0.9891 - val_loss: 0.0258 - val_acc: 0.9953\n",
            "Epoch 94/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0462 - acc: 0.9897 - val_loss: 0.0245 - val_acc: 0.9957\n",
            "Epoch 95/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0459 - acc: 0.9895 - val_loss: 0.0238 - val_acc: 0.9956\n",
            "Epoch 96/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0434 - acc: 0.9903 - val_loss: 0.0234 - val_acc: 0.9959\n",
            "Epoch 97/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0422 - acc: 0.9909 - val_loss: 0.0226 - val_acc: 0.9962\n",
            "Epoch 98/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0409 - acc: 0.9909 - val_loss: 0.0215 - val_acc: 0.9962\n",
            "Epoch 99/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0408 - acc: 0.9908 - val_loss: 0.0206 - val_acc: 0.9963\n",
            "Epoch 100/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0408 - acc: 0.9906 - val_loss: 0.0201 - val_acc: 0.9967\n",
            "Epoch 101/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0392 - acc: 0.9910 - val_loss: 0.0196 - val_acc: 0.9969\n",
            "Epoch 102/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0385 - acc: 0.9913 - val_loss: 0.0186 - val_acc: 0.9973\n",
            "Epoch 103/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0376 - acc: 0.9917 - val_loss: 0.0186 - val_acc: 0.9973\n",
            "Epoch 104/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0365 - acc: 0.9919 - val_loss: 0.0178 - val_acc: 0.9972\n",
            "Epoch 105/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0353 - acc: 0.9921 - val_loss: 0.0172 - val_acc: 0.9976\n",
            "Epoch 106/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0351 - acc: 0.9923 - val_loss: 0.0169 - val_acc: 0.9973\n",
            "Epoch 107/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0344 - acc: 0.9923 - val_loss: 0.0162 - val_acc: 0.9971\n",
            "Epoch 108/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0345 - acc: 0.9922 - val_loss: 0.0153 - val_acc: 0.9978\n",
            "Epoch 109/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0330 - acc: 0.9927 - val_loss: 0.0148 - val_acc: 0.9977\n",
            "Epoch 110/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0332 - acc: 0.9928 - val_loss: 0.0143 - val_acc: 0.9975\n",
            "Epoch 111/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0315 - acc: 0.9931 - val_loss: 0.0140 - val_acc: 0.9978\n",
            "Epoch 112/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0310 - acc: 0.9933 - val_loss: 0.0136 - val_acc: 0.9978\n",
            "Epoch 113/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0311 - acc: 0.9929 - val_loss: 0.0132 - val_acc: 0.9980\n",
            "Epoch 114/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0304 - acc: 0.9933 - val_loss: 0.0129 - val_acc: 0.9978\n",
            "Epoch 115/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0297 - acc: 0.9937 - val_loss: 0.0125 - val_acc: 0.9978\n",
            "Epoch 116/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0301 - acc: 0.9933 - val_loss: 0.0121 - val_acc: 0.9978\n",
            "Epoch 117/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0285 - acc: 0.9938 - val_loss: 0.0119 - val_acc: 0.9980\n",
            "Epoch 118/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0276 - acc: 0.9941 - val_loss: 0.0117 - val_acc: 0.9980\n",
            "Epoch 119/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0268 - acc: 0.9943 - val_loss: 0.0113 - val_acc: 0.9981\n",
            "Epoch 120/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0270 - acc: 0.9941 - val_loss: 0.0108 - val_acc: 0.9980\n",
            "Epoch 121/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0263 - acc: 0.9945 - val_loss: 0.0105 - val_acc: 0.9980\n",
            "Epoch 122/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0265 - acc: 0.9943 - val_loss: 0.0102 - val_acc: 0.9981\n",
            "Epoch 123/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0265 - acc: 0.9941 - val_loss: 0.0100 - val_acc: 0.9980\n",
            "Epoch 124/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0251 - acc: 0.9945 - val_loss: 0.0097 - val_acc: 0.9984\n",
            "Epoch 125/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0247 - acc: 0.9945 - val_loss: 0.0095 - val_acc: 0.9983\n",
            "Epoch 126/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0238 - acc: 0.9948 - val_loss: 0.0090 - val_acc: 0.9984\n",
            "Epoch 127/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0238 - acc: 0.9948 - val_loss: 0.0088 - val_acc: 0.9985\n",
            "Epoch 128/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0233 - acc: 0.9947 - val_loss: 0.0085 - val_acc: 0.9986\n",
            "Epoch 129/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0232 - acc: 0.9948 - val_loss: 0.0084 - val_acc: 0.9986\n",
            "Epoch 130/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0219 - acc: 0.9952 - val_loss: 0.0083 - val_acc: 0.9987\n",
            "Epoch 131/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0219 - acc: 0.9953 - val_loss: 0.0079 - val_acc: 0.9990\n",
            "Epoch 132/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0213 - acc: 0.9956 - val_loss: 0.0076 - val_acc: 0.9989\n",
            "Epoch 133/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0220 - acc: 0.9953 - val_loss: 0.0076 - val_acc: 0.9988\n",
            "Epoch 134/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0218 - acc: 0.9952 - val_loss: 0.0073 - val_acc: 0.9988\n",
            "Epoch 135/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0211 - acc: 0.9955 - val_loss: 0.0073 - val_acc: 0.9988\n",
            "Epoch 136/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0199 - acc: 0.9957 - val_loss: 0.0069 - val_acc: 0.9987\n",
            "Epoch 137/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0200 - acc: 0.9957 - val_loss: 0.0067 - val_acc: 0.9989\n",
            "Epoch 138/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0202 - acc: 0.9955 - val_loss: 0.0066 - val_acc: 0.9989\n",
            "Epoch 139/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0205 - acc: 0.9955 - val_loss: 0.0066 - val_acc: 0.9990\n",
            "Epoch 140/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0201 - acc: 0.9954 - val_loss: 0.0064 - val_acc: 0.9991\n",
            "Epoch 141/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0190 - acc: 0.9957 - val_loss: 0.0064 - val_acc: 0.9991\n",
            "Epoch 142/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0183 - acc: 0.9961 - val_loss: 0.0062 - val_acc: 0.9989\n",
            "Epoch 143/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0180 - acc: 0.9961 - val_loss: 0.0059 - val_acc: 0.9991\n",
            "Epoch 144/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0178 - acc: 0.9963 - val_loss: 0.0058 - val_acc: 0.9990\n",
            "Epoch 145/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0172 - acc: 0.9964 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 146/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0181 - acc: 0.9959 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 147/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0176 - acc: 0.9962 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 148/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0169 - acc: 0.9963 - val_loss: 0.0051 - val_acc: 0.9993\n",
            "Epoch 149/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0173 - acc: 0.9963 - val_loss: 0.0050 - val_acc: 0.9993\n",
            "Epoch 150/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0168 - acc: 0.9965 - val_loss: 0.0050 - val_acc: 0.9992\n",
            "Epoch 151/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0168 - acc: 0.9965 - val_loss: 0.0048 - val_acc: 0.9993\n",
            "Epoch 152/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0160 - acc: 0.9966 - val_loss: 0.0047 - val_acc: 0.9993\n",
            "Epoch 153/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0163 - acc: 0.9964 - val_loss: 0.0046 - val_acc: 0.9993\n",
            "Epoch 154/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0161 - acc: 0.9966 - val_loss: 0.0046 - val_acc: 0.9993\n",
            "Epoch 155/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0147 - acc: 0.9969 - val_loss: 0.0046 - val_acc: 0.9994\n",
            "Epoch 156/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0043 - val_acc: 0.9994\n",
            "Epoch 157/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0155 - acc: 0.9968 - val_loss: 0.0042 - val_acc: 0.9994\n",
            "Epoch 158/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0042 - val_acc: 0.9994\n",
            "Epoch 159/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0154 - acc: 0.9968 - val_loss: 0.0042 - val_acc: 0.9994\n",
            "Epoch 160/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0146 - acc: 0.9969 - val_loss: 0.0041 - val_acc: 0.9995\n",
            "Epoch 161/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0140 - acc: 0.9970 - val_loss: 0.0042 - val_acc: 0.9994\n",
            "Epoch 162/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0143 - acc: 0.9970 - val_loss: 0.0039 - val_acc: 0.9994\n",
            "Epoch 163/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0135 - acc: 0.9972 - val_loss: 0.0037 - val_acc: 0.9994\n",
            "Epoch 164/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0137 - acc: 0.9970 - val_loss: 0.0037 - val_acc: 0.9995\n",
            "Epoch 165/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0145 - acc: 0.9968 - val_loss: 0.0038 - val_acc: 0.9994\n",
            "Epoch 166/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0134 - acc: 0.9970 - val_loss: 0.0036 - val_acc: 0.9995\n",
            "Epoch 167/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0132 - acc: 0.9973 - val_loss: 0.0036 - val_acc: 0.9995\n",
            "Epoch 168/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0139 - acc: 0.9969 - val_loss: 0.0034 - val_acc: 0.9994\n",
            "Epoch 169/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0132 - acc: 0.9971 - val_loss: 0.0034 - val_acc: 0.9993\n",
            "Epoch 170/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0139 - acc: 0.9969 - val_loss: 0.0034 - val_acc: 0.9995\n",
            "Epoch 171/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0128 - acc: 0.9972 - val_loss: 0.0033 - val_acc: 0.9995\n",
            "Epoch 172/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0123 - acc: 0.9973 - val_loss: 0.0033 - val_acc: 0.9994\n",
            "Epoch 173/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0123 - acc: 0.9973 - val_loss: 0.0031 - val_acc: 0.9996\n",
            "Epoch 174/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.0030 - val_acc: 0.9996\n",
            "Epoch 175/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0117 - acc: 0.9974 - val_loss: 0.0032 - val_acc: 0.9996\n",
            "Epoch 176/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0121 - acc: 0.9973 - val_loss: 0.0030 - val_acc: 0.9996\n",
            "Epoch 177/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0119 - acc: 0.9974 - val_loss: 0.0030 - val_acc: 0.9996\n",
            "Epoch 178/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0116 - acc: 0.9976 - val_loss: 0.0029 - val_acc: 0.9995\n",
            "Epoch 179/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.0028 - val_acc: 0.9995\n",
            "Epoch 180/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0113 - acc: 0.9976 - val_loss: 0.0027 - val_acc: 0.9995\n",
            "Epoch 181/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0113 - acc: 0.9976 - val_loss: 0.0028 - val_acc: 0.9996\n",
            "Epoch 182/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0026 - val_acc: 0.9995\n",
            "Epoch 183/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0118 - acc: 0.9974 - val_loss: 0.0027 - val_acc: 0.9996\n",
            "Epoch 184/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.0026 - val_acc: 0.9996\n",
            "Epoch 185/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0111 - acc: 0.9973 - val_loss: 0.0026 - val_acc: 0.9996\n",
            "Epoch 186/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.0025 - val_acc: 0.9996\n",
            "Epoch 187/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0103 - acc: 0.9978 - val_loss: 0.0026 - val_acc: 0.9996\n",
            "Epoch 188/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0108 - acc: 0.9977 - val_loss: 0.0026 - val_acc: 0.9995\n",
            "Epoch 189/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0103 - acc: 0.9977 - val_loss: 0.0023 - val_acc: 0.9996\n",
            "Epoch 190/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0101 - acc: 0.9979 - val_loss: 0.0024 - val_acc: 0.9996\n",
            "Epoch 191/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0104 - acc: 0.9977 - val_loss: 0.0025 - val_acc: 0.9996\n",
            "Epoch 192/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0099 - acc: 0.9977 - val_loss: 0.0023 - val_acc: 0.9995\n",
            "Epoch 193/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0022 - val_acc: 0.9996\n",
            "Epoch 194/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0023 - val_acc: 0.9996\n",
            "Epoch 195/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0096 - acc: 0.9979 - val_loss: 0.0021 - val_acc: 0.9996\n",
            "Epoch 196/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0099 - acc: 0.9977 - val_loss: 0.0021 - val_acc: 0.9995\n",
            "Epoch 197/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0101 - acc: 0.9978 - val_loss: 0.0022 - val_acc: 0.9996\n",
            "Epoch 198/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0022 - val_acc: 0.9995\n",
            "Epoch 199/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0100 - acc: 0.9978 - val_loss: 0.0023 - val_acc: 0.9996\n",
            "Epoch 200/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0022 - val_acc: 0.9996\n",
            "Epoch 201/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0021 - val_acc: 0.9996\n",
            "Epoch 202/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0098 - acc: 0.9979 - val_loss: 0.0021 - val_acc: 0.9995\n",
            "Epoch 203/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0090 - acc: 0.9981 - val_loss: 0.0020 - val_acc: 0.9996\n",
            "Epoch 204/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0018 - val_acc: 0.9996\n",
            "Epoch 205/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0019 - val_acc: 0.9997\n",
            "Epoch 206/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0018 - val_acc: 0.9997\n",
            "Epoch 207/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 208/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0018 - val_acc: 0.9997\n",
            "Epoch 209/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0019 - val_acc: 0.9997\n",
            "Epoch 210/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0018 - val_acc: 0.9996\n",
            "Epoch 211/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0088 - acc: 0.9981 - val_loss: 0.0018 - val_acc: 0.9997\n",
            "Epoch 212/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0017 - val_acc: 0.9997\n",
            "Epoch 213/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 214/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0017 - val_acc: 0.9997\n",
            "Epoch 215/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0016 - val_acc: 0.9997\n",
            "Epoch 216/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 0.0017 - val_acc: 0.9997\n",
            "Epoch 217/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9997\n",
            "Epoch 218/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 219/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0017 - val_acc: 0.9997\n",
            "Epoch 220/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0016 - val_acc: 0.9997\n",
            "Epoch 221/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0080 - acc: 0.9981 - val_loss: 0.0016 - val_acc: 0.9997\n",
            "Epoch 222/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0016 - val_acc: 0.9996\n",
            "Epoch 223/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 224/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 225/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 226/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0015 - val_acc: 0.9997\n",
            "Epoch 227/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0072 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9996\n",
            "Epoch 228/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0014 - val_acc: 0.9997\n",
            "Epoch 229/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0014 - val_acc: 0.9997\n",
            "Epoch 230/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0068 - acc: 0.9985 - val_loss: 0.0014 - val_acc: 0.9997\n",
            "Epoch 231/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0069 - acc: 0.9985 - val_loss: 0.0013 - val_acc: 0.9997\n",
            "Epoch 232/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0069 - acc: 0.9985 - val_loss: 0.0014 - val_acc: 0.9997\n",
            "Epoch 233/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0014 - val_acc: 0.9997\n",
            "Epoch 234/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0073 - acc: 0.9984 - val_loss: 0.0013 - val_acc: 0.9997\n",
            "Epoch 235/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0069 - acc: 0.9985 - val_loss: 0.0013 - val_acc: 0.9997\n",
            "Epoch 236/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0013 - val_acc: 0.9997\n",
            "Epoch 237/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0013 - val_acc: 0.9997\n",
            "Epoch 238/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0014 - val_acc: 0.9996\n",
            "Epoch 239/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0072 - acc: 0.9983 - val_loss: 0.0012 - val_acc: 0.9997\n",
            "Epoch 240/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.0014 - val_acc: 0.9996\n",
            "Epoch 241/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.0012 - val_acc: 0.9997\n",
            "Epoch 242/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.0012 - val_acc: 0.9998\n",
            "Epoch 243/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.0013 - val_acc: 0.9998\n",
            "Epoch 244/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0013 - val_acc: 0.9996\n",
            "Epoch 245/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0068 - acc: 0.9983 - val_loss: 0.0013 - val_acc: 0.9997\n",
            "Epoch 246/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0013 - val_acc: 0.9997\n",
            "Epoch 247/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.0013 - val_acc: 0.9998\n",
            "Epoch 248/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.0012 - val_acc: 0.9997\n",
            "Epoch 249/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0012 - val_acc: 0.9997\n",
            "Epoch 250/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 0.0012 - val_acc: 0.9997\n",
            "Epoch 251/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.0011 - val_acc: 0.9997\n",
            "Epoch 252/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 0.9997\n",
            "Epoch 253/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0059 - acc: 0.9986 - val_loss: 0.0011 - val_acc: 0.9997\n",
            "Epoch 254/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0059 - acc: 0.9986 - val_loss: 0.0011 - val_acc: 0.9998\n",
            "Epoch 255/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0011 - val_acc: 0.9997\n",
            "Epoch 256/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0062 - acc: 0.9985 - val_loss: 0.0011 - val_acc: 0.9997\n",
            "Epoch 257/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0055 - acc: 0.9989 - val_loss: 0.0011 - val_acc: 0.9997\n",
            "Epoch 258/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.0011 - val_acc: 0.9997\n",
            "Epoch 259/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0054 - acc: 0.9989 - val_loss: 0.0012 - val_acc: 0.9997\n",
            "Epoch 260/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0010 - val_acc: 0.9997\n",
            "Epoch 261/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 0.9997\n",
            "Epoch 262/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0010 - val_acc: 0.9997\n",
            "Epoch 263/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0056 - acc: 0.9987 - val_loss: 9.6400e-04 - val_acc: 0.9998\n",
            "Epoch 264/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 9.7894e-04 - val_acc: 0.9997\n",
            "Epoch 265/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 9.6864e-04 - val_acc: 0.9997\n",
            "Epoch 266/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 9.9910e-04 - val_acc: 0.9997\n",
            "Epoch 267/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 9.8843e-04 - val_acc: 0.9998\n",
            "Epoch 268/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0057 - acc: 0.9986 - val_loss: 8.6380e-04 - val_acc: 0.9998\n",
            "Epoch 269/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 9.8092e-04 - val_acc: 0.9998\n",
            "Epoch 270/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 8.7071e-04 - val_acc: 0.9998\n",
            "Epoch 271/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 9.2891e-04 - val_acc: 0.9997\n",
            "Epoch 272/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0010 - val_acc: 0.9997\n",
            "Epoch 273/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0058 - acc: 0.9987 - val_loss: 8.8330e-04 - val_acc: 0.9998\n",
            "Epoch 274/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 8.8547e-04 - val_acc: 0.9997\n",
            "Epoch 275/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0053 - acc: 0.9988 - val_loss: 9.7465e-04 - val_acc: 0.9997\n",
            "Epoch 276/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 9.0594e-04 - val_acc: 0.9997\n",
            "Epoch 277/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 8.7522e-04 - val_acc: 0.9997\n",
            "Epoch 278/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0059 - acc: 0.9986 - val_loss: 8.9642e-04 - val_acc: 0.9997\n",
            "Epoch 279/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 8.5632e-04 - val_acc: 0.9997\n",
            "Epoch 280/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 8.9638e-04 - val_acc: 0.9997\n",
            "Epoch 281/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0048 - acc: 0.9989 - val_loss: 9.1581e-04 - val_acc: 0.9997\n",
            "Epoch 282/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0051 - acc: 0.9989 - val_loss: 8.9294e-04 - val_acc: 0.9997\n",
            "Epoch 283/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 8.7391e-04 - val_acc: 0.9997\n",
            "Epoch 284/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0056 - acc: 0.9987 - val_loss: 9.8829e-04 - val_acc: 0.9997\n",
            "Epoch 285/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 8.9577e-04 - val_acc: 0.9997\n",
            "Epoch 286/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 7.7451e-04 - val_acc: 0.9998\n",
            "Epoch 287/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 9.3363e-04 - val_acc: 0.9997\n",
            "Epoch 288/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 8.6931e-04 - val_acc: 0.9997\n",
            "Epoch 289/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 8.7639e-04 - val_acc: 0.9997\n",
            "Epoch 290/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0047 - acc: 0.9990 - val_loss: 7.5808e-04 - val_acc: 0.9997\n",
            "Epoch 291/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 7.9741e-04 - val_acc: 0.9997\n",
            "Epoch 292/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0048 - acc: 0.9989 - val_loss: 8.8264e-04 - val_acc: 0.9997\n",
            "Epoch 293/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 7.9720e-04 - val_acc: 0.9997\n",
            "Epoch 294/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 8.3610e-04 - val_acc: 0.9997\n",
            "Epoch 295/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 8.9121e-04 - val_acc: 0.9997\n",
            "Epoch 296/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 7.7656e-04 - val_acc: 0.9997\n",
            "Epoch 297/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 7.6779e-04 - val_acc: 0.9997\n",
            "Epoch 298/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0047 - acc: 0.9989 - val_loss: 7.8927e-04 - val_acc: 0.9997\n",
            "Epoch 299/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0048 - acc: 0.9989 - val_loss: 7.6130e-04 - val_acc: 0.9997\n",
            "Epoch 300/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0047 - acc: 0.9989 - val_loss: 8.8499e-04 - val_acc: 0.9998\n",
            "Epoch 301/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0048 - acc: 0.9989 - val_loss: 8.7470e-04 - val_acc: 0.9997\n",
            "Epoch 302/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 7.9934e-04 - val_acc: 0.9997\n",
            "Epoch 303/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 8.5081e-04 - val_acc: 0.9997\n",
            "Epoch 304/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 7.7844e-04 - val_acc: 0.9997\n",
            "Epoch 305/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 7.9975e-04 - val_acc: 0.9997\n",
            "Epoch 306/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0046 - acc: 0.9989 - val_loss: 7.8434e-04 - val_acc: 0.9997\n",
            "Epoch 307/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 7.9829e-04 - val_acc: 0.9997\n",
            "Epoch 308/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 7.8857e-04 - val_acc: 0.9997\n",
            "Epoch 309/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 5.7068e-04 - val_acc: 0.9998\n",
            "Epoch 310/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 6.4636e-04 - val_acc: 0.9997\n",
            "Epoch 311/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 8.0931e-04 - val_acc: 0.9997\n",
            "Epoch 312/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 6.4634e-04 - val_acc: 0.9998\n",
            "Epoch 313/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 6.8360e-04 - val_acc: 0.9998\n",
            "Epoch 314/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 6.8128e-04 - val_acc: 0.9998\n",
            "Epoch 315/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 7.2523e-04 - val_acc: 0.9997\n",
            "Epoch 316/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 7.3953e-04 - val_acc: 0.9998\n",
            "Epoch 317/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 6.9989e-04 - val_acc: 0.9998\n",
            "Epoch 318/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 6.4196e-04 - val_acc: 0.9997\n",
            "Epoch 319/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0038 - acc: 0.9993 - val_loss: 7.0151e-04 - val_acc: 0.9997\n",
            "Epoch 320/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 6.1106e-04 - val_acc: 0.9997\n",
            "Epoch 321/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0044 - acc: 0.9989 - val_loss: 7.3723e-04 - val_acc: 0.9997\n",
            "Epoch 322/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 6.3279e-04 - val_acc: 0.9997\n",
            "Epoch 323/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0040 - acc: 0.9992 - val_loss: 6.0770e-04 - val_acc: 0.9998\n",
            "Epoch 324/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0044 - acc: 0.9989 - val_loss: 6.3269e-04 - val_acc: 0.9998\n",
            "Epoch 325/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 7.2708e-04 - val_acc: 0.9998\n",
            "Epoch 326/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0037 - acc: 0.9992 - val_loss: 7.3141e-04 - val_acc: 0.9998\n",
            "Epoch 327/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 8.1663e-04 - val_acc: 0.9997\n",
            "Epoch 328/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 6.8926e-04 - val_acc: 0.9997\n",
            "Epoch 329/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 6.6830e-04 - val_acc: 0.9997\n",
            "Epoch 330/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 7.7688e-04 - val_acc: 0.9998\n",
            "Epoch 331/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 6.3805e-04 - val_acc: 0.9998\n",
            "Epoch 332/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 6.4419e-04 - val_acc: 0.9998\n",
            "Epoch 333/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 6.1325e-04 - val_acc: 0.9998\n",
            "Epoch 334/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 6.8910e-04 - val_acc: 0.9998\n",
            "Epoch 335/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0036 - acc: 0.9993 - val_loss: 7.3340e-04 - val_acc: 0.9997\n",
            "Epoch 336/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 5.6764e-04 - val_acc: 0.9998\n",
            "Epoch 337/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 6.3847e-04 - val_acc: 0.9998\n",
            "Epoch 338/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 5.9143e-04 - val_acc: 0.9998\n",
            "Epoch 339/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 6.6830e-04 - val_acc: 0.9998\n",
            "Epoch 340/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 6.7873e-04 - val_acc: 0.9998\n",
            "Epoch 341/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 5.2005e-04 - val_acc: 0.9998\n",
            "Epoch 342/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 6.1837e-04 - val_acc: 0.9998\n",
            "Epoch 343/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 5.7736e-04 - val_acc: 0.9998\n",
            "Epoch 344/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 5.1944e-04 - val_acc: 0.9998\n",
            "Epoch 345/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 5.7566e-04 - val_acc: 0.9998\n",
            "Epoch 346/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 6.3936e-04 - val_acc: 0.9998\n",
            "Epoch 347/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 5.8436e-04 - val_acc: 0.9998\n",
            "Epoch 348/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 6.4728e-04 - val_acc: 0.9998\n",
            "Epoch 349/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 6.1081e-04 - val_acc: 0.9998\n",
            "Epoch 350/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 5.2928e-04 - val_acc: 0.9998\n",
            "Epoch 351/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 5.4904e-04 - val_acc: 0.9998\n",
            "Epoch 352/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 7.1365e-04 - val_acc: 0.9998\n",
            "Epoch 353/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 6.4430e-04 - val_acc: 0.9998\n",
            "Epoch 354/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 5.5800e-04 - val_acc: 0.9998\n",
            "Epoch 355/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 6.0052e-04 - val_acc: 0.9998\n",
            "Epoch 356/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 5.5916e-04 - val_acc: 0.9998\n",
            "Epoch 357/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 5.5370e-04 - val_acc: 0.9998\n",
            "Epoch 358/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 5.6514e-04 - val_acc: 0.9998\n",
            "Epoch 359/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 5.9379e-04 - val_acc: 0.9998\n",
            "Epoch 360/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0034 - acc: 0.9993 - val_loss: 5.3282e-04 - val_acc: 0.9998\n",
            "Epoch 361/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 5.8641e-04 - val_acc: 0.9998\n",
            "Epoch 362/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 6.2746e-04 - val_acc: 0.9998\n",
            "Epoch 363/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 6.5532e-04 - val_acc: 0.9998\n",
            "Epoch 364/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 5.4827e-04 - val_acc: 0.9998\n",
            "Epoch 365/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 6.3734e-04 - val_acc: 0.9998\n",
            "Epoch 366/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 6.2886e-04 - val_acc: 0.9998\n",
            "Epoch 367/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 5.6951e-04 - val_acc: 0.9998\n",
            "Epoch 368/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 6.0751e-04 - val_acc: 0.9998\n",
            "Epoch 369/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 5.7082e-04 - val_acc: 0.9998\n",
            "Epoch 370/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 6.0842e-04 - val_acc: 0.9998\n",
            "Epoch 371/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 5.6917e-04 - val_acc: 0.9998\n",
            "Epoch 372/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 5.6063e-04 - val_acc: 0.9998\n",
            "Epoch 373/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 5.2635e-04 - val_acc: 0.9998\n",
            "Epoch 374/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 5.2465e-04 - val_acc: 0.9998\n",
            "Epoch 375/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 5.7449e-04 - val_acc: 0.9998\n",
            "Epoch 376/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 5.2338e-04 - val_acc: 0.9998\n",
            "Epoch 377/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 5.4636e-04 - val_acc: 0.9998\n",
            "Epoch 378/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 4.9189e-04 - val_acc: 0.9998\n",
            "Epoch 379/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 5.6704e-04 - val_acc: 0.9998\n",
            "Epoch 380/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 6.2139e-04 - val_acc: 0.9998\n",
            "Epoch 381/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 5.0743e-04 - val_acc: 0.9998\n",
            "Epoch 382/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 4.8895e-04 - val_acc: 0.9998\n",
            "Epoch 383/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 5.2477e-04 - val_acc: 0.9998\n",
            "Epoch 384/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 5.0075e-04 - val_acc: 0.9998\n",
            "Epoch 385/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 5.5319e-04 - val_acc: 0.9998\n",
            "Epoch 386/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 5.9386e-04 - val_acc: 0.9998\n",
            "Epoch 387/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 5.9656e-04 - val_acc: 0.9998\n",
            "Epoch 388/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 5.2908e-04 - val_acc: 0.9998\n",
            "Epoch 389/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 6.2609e-04 - val_acc: 0.9998\n",
            "Epoch 390/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 5.2484e-04 - val_acc: 0.9998\n",
            "Epoch 391/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 5.9480e-04 - val_acc: 0.9998\n",
            "Epoch 392/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 5.7715e-04 - val_acc: 0.9998\n",
            "Epoch 393/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 4.8605e-04 - val_acc: 0.9998\n",
            "Epoch 394/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 5.3274e-04 - val_acc: 0.9998\n",
            "Epoch 395/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 5.5445e-04 - val_acc: 0.9998\n",
            "Epoch 396/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 6.5263e-04 - val_acc: 0.9998\n",
            "Epoch 397/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 6.4846e-04 - val_acc: 0.9998\n",
            "Epoch 398/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 5.5635e-04 - val_acc: 0.9998\n",
            "Epoch 399/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 6.4751e-04 - val_acc: 0.9998\n",
            "Epoch 400/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 5.7981e-04 - val_acc: 0.9998\n",
            "Epoch 401/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 5.5086e-04 - val_acc: 0.9998\n",
            "Epoch 402/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 6.2565e-04 - val_acc: 0.9998\n",
            "Epoch 403/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 5.7952e-04 - val_acc: 0.9998\n",
            "Epoch 404/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 5.7726e-04 - val_acc: 0.9998\n",
            "Epoch 405/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 6.5203e-04 - val_acc: 0.9998\n",
            "Epoch 406/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 5.2372e-04 - val_acc: 0.9998\n",
            "Epoch 407/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 3.9514e-04 - val_acc: 0.9998\n",
            "Epoch 408/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 5.1805e-04 - val_acc: 0.9998\n",
            "Epoch 409/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 6.0349e-04 - val_acc: 0.9998\n",
            "Epoch 410/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 5.6883e-04 - val_acc: 0.9998\n",
            "Epoch 411/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 5.4085e-04 - val_acc: 0.9998\n",
            "Epoch 412/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 6.2986e-04 - val_acc: 0.9998\n",
            "Epoch 413/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 5.0349e-04 - val_acc: 0.9998\n",
            "Epoch 414/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 4.9304e-04 - val_acc: 0.9998\n",
            "Epoch 415/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 5.6307e-04 - val_acc: 0.9998\n",
            "Epoch 416/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 4.5415e-04 - val_acc: 0.9998\n",
            "Epoch 417/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 5.2159e-04 - val_acc: 0.9998\n",
            "Epoch 418/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 4.3642e-04 - val_acc: 0.9998\n",
            "Epoch 419/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 5.0861e-04 - val_acc: 0.9998\n",
            "Epoch 420/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 4.7564e-04 - val_acc: 0.9998\n",
            "Epoch 421/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 4.1153e-04 - val_acc: 0.9998\n",
            "Epoch 422/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 5.1797e-04 - val_acc: 0.9998\n",
            "Epoch 423/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 6.0706e-04 - val_acc: 0.9998\n",
            "Epoch 424/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 5.1286e-04 - val_acc: 0.9998\n",
            "Epoch 425/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 5.6154e-04 - val_acc: 0.9998\n",
            "Epoch 426/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 5.6555e-04 - val_acc: 0.9998\n",
            "Epoch 427/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 4.2063e-04 - val_acc: 0.9998\n",
            "Epoch 428/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 4.7378e-04 - val_acc: 0.9998\n",
            "Epoch 429/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 6.7407e-04 - val_acc: 0.9998\n",
            "Epoch 430/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 5.2336e-04 - val_acc: 0.9998\n",
            "Epoch 431/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 5.8893e-04 - val_acc: 0.9998\n",
            "Epoch 432/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 5.8803e-04 - val_acc: 0.9998\n",
            "Epoch 433/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 4.8646e-04 - val_acc: 0.9998\n",
            "Epoch 434/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 4.9892e-04 - val_acc: 0.9998\n",
            "Epoch 435/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 5.1629e-04 - val_acc: 0.9998\n",
            "Epoch 436/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 5.5532e-04 - val_acc: 0.9998\n",
            "Epoch 437/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 5.3300e-04 - val_acc: 0.9998\n",
            "Epoch 438/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 5.5886e-04 - val_acc: 0.9998\n",
            "Epoch 439/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 6.0456e-04 - val_acc: 0.9998\n",
            "Epoch 440/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 5.5662e-04 - val_acc: 0.9998\n",
            "Epoch 441/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 5.3205e-04 - val_acc: 0.9998\n",
            "Epoch 442/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 5.3918e-04 - val_acc: 0.9998\n",
            "Epoch 443/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 4.6327e-04 - val_acc: 0.9998\n",
            "Epoch 444/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 4.3504e-04 - val_acc: 0.9998\n",
            "Epoch 445/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 4.8864e-04 - val_acc: 0.9998\n",
            "Epoch 446/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 4.6801e-04 - val_acc: 0.9998\n",
            "Epoch 447/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 4.4735e-04 - val_acc: 0.9998\n",
            "Epoch 448/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 5.0063e-04 - val_acc: 0.9998\n",
            "Epoch 449/500\n",
            "7083/7083 [==============================] - 46s 7ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 5.5320e-04 - val_acc: 0.9998\n",
            "Epoch 450/500\n",
            "7083/7083 [==============================] - 48s 7ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 5.6810e-04 - val_acc: 0.9998\n",
            "Epoch 451/500\n",
            "7083/7083 [==============================] - 46s 7ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 3.9734e-04 - val_acc: 0.9998\n",
            "Epoch 452/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 4.4702e-04 - val_acc: 0.9998\n",
            "Epoch 453/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 4.5329e-04 - val_acc: 0.9998\n",
            "Epoch 454/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 5.4689e-04 - val_acc: 0.9998\n",
            "Epoch 455/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 5.4557e-04 - val_acc: 0.9998\n",
            "Epoch 456/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 4.0351e-04 - val_acc: 0.9998\n",
            "Epoch 457/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 5.6282e-04 - val_acc: 0.9998\n",
            "Epoch 458/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 6.1522e-04 - val_acc: 0.9998\n",
            "Epoch 459/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 4.6295e-04 - val_acc: 0.9998\n",
            "Epoch 460/500\n",
            "7083/7083 [==============================] - 46s 6ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 4.2358e-04 - val_acc: 0.9998\n",
            "Epoch 461/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 5.0107e-04 - val_acc: 0.9998\n",
            "Epoch 462/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 5.0152e-04 - val_acc: 0.9998\n",
            "Epoch 463/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 4.3442e-04 - val_acc: 0.9998\n",
            "Epoch 464/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 4.8959e-04 - val_acc: 0.9998\n",
            "Epoch 465/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 4.2333e-04 - val_acc: 0.9998\n",
            "Epoch 466/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 4.2563e-04 - val_acc: 0.9998\n",
            "Epoch 467/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 4.7026e-04 - val_acc: 0.9998\n",
            "Epoch 468/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 4.3642e-04 - val_acc: 0.9998\n",
            "Epoch 469/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 5.2312e-04 - val_acc: 0.9998\n",
            "Epoch 470/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 4.6967e-04 - val_acc: 0.9998\n",
            "Epoch 471/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 4.9448e-04 - val_acc: 0.9998\n",
            "Epoch 472/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 4.4225e-04 - val_acc: 0.9998\n",
            "Epoch 473/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 4.3040e-04 - val_acc: 0.9998\n",
            "Epoch 474/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 4.3469e-04 - val_acc: 0.9999\n",
            "Epoch 475/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 4.8954e-04 - val_acc: 0.9998\n",
            "Epoch 476/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 3.7370e-04 - val_acc: 0.9998\n",
            "Epoch 477/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 4.9547e-04 - val_acc: 0.9998\n",
            "Epoch 478/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 4.1476e-04 - val_acc: 0.9999\n",
            "Epoch 479/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 4.2906e-04 - val_acc: 0.9998\n",
            "Epoch 480/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 3.5556e-04 - val_acc: 0.9998\n",
            "Epoch 481/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 4.1732e-04 - val_acc: 0.9998\n",
            "Epoch 482/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 3.2677e-04 - val_acc: 0.9999\n",
            "Epoch 483/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 4.0999e-04 - val_acc: 0.9998\n",
            "Epoch 484/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 4.2960e-04 - val_acc: 0.9998\n",
            "Epoch 485/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 4.3532e-04 - val_acc: 0.9998\n",
            "Epoch 486/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 4.2752e-04 - val_acc: 0.9998\n",
            "Epoch 487/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 4.3350e-04 - val_acc: 0.9999\n",
            "Epoch 488/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 4.5545e-04 - val_acc: 0.9998\n",
            "Epoch 489/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 4.3800e-04 - val_acc: 0.9998\n",
            "Epoch 490/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 5.0745e-04 - val_acc: 0.9998\n",
            "Epoch 491/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 4.8423e-04 - val_acc: 0.9998\n",
            "Epoch 492/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 3.8777e-04 - val_acc: 0.9998\n",
            "Epoch 493/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 4.0803e-04 - val_acc: 0.9999\n",
            "Epoch 494/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 4.4301e-04 - val_acc: 0.9998\n",
            "Epoch 495/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 3.5053e-04 - val_acc: 0.9998\n",
            "Epoch 496/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 4.0310e-04 - val_acc: 0.9998\n",
            "Epoch 497/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 4.7314e-04 - val_acc: 0.9998\n",
            "Epoch 498/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 5.1373e-04 - val_acc: 0.9998\n",
            "Epoch 499/500\n",
            "7083/7083 [==============================] - 44s 6ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 3.7717e-04 - val_acc: 0.9998\n",
            "Epoch 500/500\n",
            "7083/7083 [==============================] - 45s 6ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 4.1784e-04 - val_acc: 0.9998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff34105e310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYce4zecq2xO"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/data/input_output/version_1/all_error_v5.h1\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}